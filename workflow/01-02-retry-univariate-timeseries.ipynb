{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>OpenInt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-05-18</td>\n      <td>42.05</td>\n      <td>45.00</td>\n      <td>38.00</td>\n      <td>38.23</td>\n      <td>580438450</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-05-21</td>\n      <td>36.53</td>\n      <td>36.66</td>\n      <td>33.00</td>\n      <td>34.03</td>\n      <td>169418988</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-05-22</td>\n      <td>32.61</td>\n      <td>33.59</td>\n      <td>30.94</td>\n      <td>31.00</td>\n      <td>101876406</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-05-23</td>\n      <td>31.37</td>\n      <td>32.50</td>\n      <td>31.36</td>\n      <td>32.00</td>\n      <td>73678512</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-05-24</td>\n      <td>32.95</td>\n      <td>33.21</td>\n      <td>31.77</td>\n      <td>33.03</td>\n      <td>42560731</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date   Open   High    Low  Close     Volume  OpenInt\n0  2012-05-18  42.05  45.00  38.00  38.23  580438450        0\n1  2012-05-21  36.53  36.66  33.00  34.03  169418988        0\n2  2012-05-22  32.61  33.59  30.94  31.00  101876406        0\n3  2012-05-23  31.37  32.50  31.36  32.00   73678512        0\n4  2012-05-24  32.95  33.21  31.77  33.03   42560731        0"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../inputData/fb.us.txt')\n",
    "#data.Date = pd.to_datetime(fb_stocks.Date)\n",
    "#data.drop(columns='OpenInt', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcol = fb_stocks.columns[1:]\n",
    "scaled = MinMaxScaler().fit_transform(fb_stocks[Xcol])\n",
    "dataSc = pd.DataFrame(data=scaled, columns=Xcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.124295</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>0.976869</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.986137</td>\n",
       "      <td>0.984903</td>\n",
       "      <td>0.012815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>0.988678</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.985388</td>\n",
       "      <td>0.012168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.984356</td>\n",
       "      <td>0.984511</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.981204</td>\n",
       "      <td>0.007928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.011643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>0.975590</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>0.983990</td>\n",
       "      <td>0.974535</td>\n",
       "      <td>0.008959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1381 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close    Volume\n",
       "0     0.145909  0.162364  0.125445  0.124295  1.000000\n",
       "1     0.112308  0.111705  0.094774  0.098830  0.284593\n",
       "2     0.088447  0.093057  0.082137  0.080458  0.167031\n",
       "3     0.080898  0.086436  0.084714  0.086522  0.117950\n",
       "4     0.090516  0.090749  0.087229  0.092767  0.063788\n",
       "...        ...       ...       ...       ...       ...\n",
       "1376  0.976869  0.985118  0.986137  0.984903  0.012815\n",
       "1377  0.988678  0.986928  0.992841  0.985388  0.012168\n",
       "1378  0.984356  0.984511  0.991044  0.981204  0.007928\n",
       "1379  0.975347  0.978740  0.978653  0.979628  0.011643\n",
       "1380  0.975590  0.976918  0.983990  0.974535  0.008959\n",
       "\n",
       "[1381 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = TimeseriesGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following example of how to make multivariate timeseries\n",
    "https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "\n",
    "# reshape series\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15],\n",
       "       [ 20,  25],\n",
       "       [ 30,  35],\n",
       "       [ 40,  45],\n",
       "       [ 50,  55],\n",
       "       [ 60,  65],\n",
       "       [ 70,  75],\n",
       "       [ 80,  85],\n",
       "       [ 90,  95],\n",
       "       [100, 105]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14590942, 0.16236409, 0.12544473, 0.12429516, 1.        ],\n",
       "       [0.11230825, 0.11170504, 0.09477365, 0.09882981, 0.28459312],\n",
       "       [0.08844655, 0.09305716, 0.08213716, 0.08045838, 0.16703073],\n",
       "       ...,\n",
       "       [0.98435598, 0.98451072, 0.99104404, 0.98120415, 0.0079276 ],\n",
       "       [0.97534697, 0.97874021, 0.97865293, 0.97962772, 0.01164298],\n",
       "       [0.97559046, 0.97691794, 0.98398969, 0.97453465, 0.00895932]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSc.iloc[:,:2]\n",
    "np.array(dataSc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>0.679328</td>\n",
       "      <td>0.682925</td>\n",
       "      <td>0.684885</td>\n",
       "      <td>0.682168</td>\n",
       "      <td>0.014711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>0.682676</td>\n",
       "      <td>0.682561</td>\n",
       "      <td>0.678935</td>\n",
       "      <td>0.673801</td>\n",
       "      <td>0.018485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>0.675250</td>\n",
       "      <td>0.676608</td>\n",
       "      <td>0.680346</td>\n",
       "      <td>0.674953</td>\n",
       "      <td>0.007169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>0.670380</td>\n",
       "      <td>0.668043</td>\n",
       "      <td>0.669856</td>\n",
       "      <td>0.667495</td>\n",
       "      <td>0.018037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>0.672084</td>\n",
       "      <td>0.672295</td>\n",
       "      <td>0.674948</td>\n",
       "      <td>0.667859</td>\n",
       "      <td>0.010866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close    Volume\n",
       "1105  0.679328  0.682925  0.684885  0.682168  0.014711\n",
       "1106  0.682676  0.682561  0.678935  0.673801  0.018485\n",
       "1107  0.675250  0.676608  0.680346  0.674953  0.007169\n",
       "1108  0.670380  0.668043  0.669856  0.667495  0.018037\n",
       "1109  0.672084  0.672295  0.674948  0.667859  0.010866"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine where the index separating the training from the test set is. We will start with a 80% train/test split.\n",
    "divIndex = round(dataSc.shape[0] * 0.8)\n",
    "divIndex\n",
    "train = dataSc.iloc[:divIndex,:]\n",
    "test = dataSc.iloc[divIndex:,:]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "n_input = 20\n",
    "seqTrain = TimeseriesGenerator(data=np.array(train), targets=np.array(train.Open), length=20, batch_size=30) #end_index=divIndex\n",
    "seqTest = TimeseriesGenerator(data=np.array(test), targets=np.array(test.Open), length=20, batch_size=30) #start_index=divIndex + 1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105, 5)\n",
      "(1105,)\n"
     ]
    }
   ],
   "source": [
    "print(seqTrain.data.shape)\n",
    "print(seqTrain.targets.shape)\n",
    "#stepsEpochTrain = len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0.14590942, 0.16236409, 0.12544473, 0.12429516, 1.        ],\n",
       "        [0.11230825, 0.11170504, 0.09477365, 0.09882981, 0.28459312],\n",
       "        [0.08844655, 0.09305716, 0.08213716, 0.08045838, 0.16703073],\n",
       "        ...,\n",
       "        [0.67062333, 0.67138432, 0.67648141, 0.67143637, 0.0105741 ],\n",
       "        [0.67171902, 0.67296362, 0.67801497, 0.67307343, 0.0093091 ],\n",
       "        [0.67543219, 0.67411772, 0.67954852, 0.67458922, 0.01034104]]),\n",
       " 'targets': array([0.14590942, 0.11230825, 0.08844655, ..., 0.67062333, 0.67171902,\n",
       "        0.67543219]),\n",
       " 'length': 20,\n",
       " 'sampling_rate': 1,\n",
       " 'stride': 1,\n",
       " 'start_index': 20,\n",
       " 'end_index': 1104,\n",
       " 'shuffle': False,\n",
       " 'reverse': False,\n",
       " 'batch_size': 30}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqTrain.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-dd780ef03306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseqTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sequence_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "seqTrain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our training and testsequence, so we can move to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = train.shape[1]\n",
    "\n",
    "model1 = Sequential([\n",
    "    layers.LSTM(100, activation='relu', input_shape=(1105, 20 ,5)),   \n",
    "])\n",
    "\n",
    "# layers.Dropout(0.5),\n",
    "# layers.Dense(50, activation='elu'),\n",
    "# layers.Dropout(0.5),\n",
    "# layers.Dense(2, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc'])\n",
    "#steps_per_epoch = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_17_input to have 3 dimensions, but got array with shape (1105, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-ff3b5ac4b5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_17_input to have 3 dimensions, but got array with shape (1105, 5)"
     ]
    }
   ],
   "source": [
    "model1.fit(x=seqTrain.data, y=seqTrain.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected lstm_17 to have shape (100,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-edd3e6eb5262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model1.fit_generator(generator=seqTrain,\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                      )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected lstm_17 to have shape (100,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model1.fit_generator(generator=seqTrain,\n",
    "                     \n",
    "                     epochs=10, \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.124295</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>0.976869</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.986137</td>\n",
       "      <td>0.984903</td>\n",
       "      <td>0.012815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>0.988678</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.985388</td>\n",
       "      <td>0.012168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.984356</td>\n",
       "      <td>0.984511</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.981204</td>\n",
       "      <td>0.007928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.011643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>0.975590</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>0.983990</td>\n",
       "      <td>0.974535</td>\n",
       "      <td>0.008959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1381 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close    Volume\n",
       "0     0.145909  0.162364  0.125445  0.124295  1.000000\n",
       "1     0.112308  0.111705  0.094774  0.098830  0.284593\n",
       "2     0.088447  0.093057  0.082137  0.080458  0.167031\n",
       "3     0.080898  0.086436  0.084714  0.086522  0.117950\n",
       "4     0.090516  0.090749  0.087229  0.092767  0.063788\n",
       "...        ...       ...       ...       ...       ...\n",
       "1376  0.976869  0.985118  0.986137  0.984903  0.012815\n",
       "1377  0.988678  0.986928  0.992841  0.985388  0.012168\n",
       "1378  0.984356  0.984511  0.991044  0.981204  0.007928\n",
       "1379  0.975347  0.978740  0.978653  0.979628  0.011643\n",
       "1380  0.975590  0.976918  0.983990  0.974535  0.008959\n",
       "\n",
       "[1381 rows x 5 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features\n",
    "input_feature= dataSc.iloc[:,:n_features].values\n",
    "input_data = input_feature\n",
    "stock_data = dataSc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 50\n",
    "test_size=int(.3 * len(stock_data))\n",
    "X=[]\n",
    "y=[]\n",
    "for i in range(len(stock_data)-lookback-1):\n",
    "    t=[]\n",
    "    for j in range(0,lookback):\n",
    "        t.append(input_data[[(i+j)], :])\n",
    "    X.append(t)\n",
    "    y.append(input_data[i+ lookback,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330, 50, 5)\n",
      "(464, 50, 5)\n"
     ]
    }
   ],
   "source": [
    "X, y= np.array(X), np.array(y)\n",
    "X_test = X[:test_size+lookback]\n",
    "X = X.reshape(X.shape[0],lookback, n_features)\n",
    "X_test = X_test.reshape(X_test.shape[0],lookback, n_features)\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.shape[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 50, 30)            3960      \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 50, 30)            7320      \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,631\n",
      "Trainable params: 18,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=30, return_sequences= True, input_shape=(X.shape[1],2)))\n",
    "model.add(LSTM(units=30, return_sequences=True))\n",
    "model.add(LSTM(units=30))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3897d0c650>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-30)</th>\n",
       "      <th>var2(t-30)</th>\n",
       "      <th>var3(t-30)</th>\n",
       "      <th>var4(t-30)</th>\n",
       "      <th>var5(t-30)</th>\n",
       "      <th>var1(t-29)</th>\n",
       "      <th>var2(t-29)</th>\n",
       "      <th>var3(t-29)</th>\n",
       "      <th>var4(t-29)</th>\n",
       "      <th>var5(t-29)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.124295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084246</td>\n",
       "      <td>0.083338</td>\n",
       "      <td>0.081033</td>\n",
       "      <td>0.081004</td>\n",
       "      <td>0.023681</td>\n",
       "      <td>0.080168</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>0.079064</td>\n",
       "      <td>0.014299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080168</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>0.079064</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.078098</td>\n",
       "      <td>0.079998</td>\n",
       "      <td>0.081278</td>\n",
       "      <td>0.081671</td>\n",
       "      <td>0.004965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078098</td>\n",
       "      <td>0.079998</td>\n",
       "      <td>0.081278</td>\n",
       "      <td>0.081671</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.080351</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.082628</td>\n",
       "      <td>0.083308</td>\n",
       "      <td>0.007174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080351</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.082628</td>\n",
       "      <td>0.083308</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.084884</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>0.090212</td>\n",
       "      <td>0.089170</td>\n",
       "      <td>0.083180</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.084884</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.088578</td>\n",
       "      <td>0.087552</td>\n",
       "      <td>0.020643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>0.920136</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>0.883389</td>\n",
       "      <td>0.880010</td>\n",
       "      <td>0.061440</td>\n",
       "      <td>0.891283</td>\n",
       "      <td>0.894308</td>\n",
       "      <td>0.890872</td>\n",
       "      <td>0.888134</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981312</td>\n",
       "      <td>0.981534</td>\n",
       "      <td>0.976322</td>\n",
       "      <td>0.977324</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.976869</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.986137</td>\n",
       "      <td>0.984903</td>\n",
       "      <td>0.012815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>0.891283</td>\n",
       "      <td>0.894308</td>\n",
       "      <td>0.890872</td>\n",
       "      <td>0.888134</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>0.899805</td>\n",
       "      <td>0.911559</td>\n",
       "      <td>0.907987</td>\n",
       "      <td>0.909174</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976869</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.986137</td>\n",
       "      <td>0.984903</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.988678</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.985388</td>\n",
       "      <td>0.012168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.899805</td>\n",
       "      <td>0.911559</td>\n",
       "      <td>0.907987</td>\n",
       "      <td>0.909174</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.917740</td>\n",
       "      <td>0.915540</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988678</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.985388</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.984356</td>\n",
       "      <td>0.984511</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.981204</td>\n",
       "      <td>0.007928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.917740</td>\n",
       "      <td>0.915540</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.917641</td>\n",
       "      <td>0.931726</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.928515</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984356</td>\n",
       "      <td>0.984511</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.981204</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.011643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>0.917641</td>\n",
       "      <td>0.931726</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.928515</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.933224</td>\n",
       "      <td>0.933001</td>\n",
       "      <td>0.927494</td>\n",
       "      <td>0.920027</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.975590</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>0.983990</td>\n",
       "      <td>0.974535</td>\n",
       "      <td>0.008959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1351 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-30)  var2(t-30)  var3(t-30)  var4(t-30)  var5(t-30)  var1(t-29)  \\\n",
       "30      0.145909    0.162364    0.125445    0.124295    1.000000    0.112308   \n",
       "31      0.112308    0.111705    0.094774    0.098830    0.284593    0.088447   \n",
       "32      0.088447    0.093057    0.082137    0.080458    0.167031    0.080898   \n",
       "33      0.080898    0.086436    0.084714    0.086522    0.117950    0.090516   \n",
       "34      0.090516    0.090749    0.087229    0.092767    0.063788    0.090212   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1376    0.920136    0.917391    0.883389    0.880010    0.061440    0.891283   \n",
       "1377    0.891283    0.894308    0.890872    0.888134    0.030330    0.899805   \n",
       "1378    0.899805    0.911559    0.907987    0.909174    0.023040    0.912223   \n",
       "1379    0.912223    0.915993    0.917740    0.915540    0.010876    0.917641   \n",
       "1380    0.917641    0.931726    0.927862    0.928515    0.016342    0.933224   \n",
       "\n",
       "      var2(t-29)  var3(t-29)  var4(t-29)  var5(t-29)  ...  var1(t-1)  \\\n",
       "30      0.111705    0.094774    0.098830    0.284593  ...   0.084246   \n",
       "31      0.093057    0.082137    0.080458    0.167031  ...   0.080168   \n",
       "32      0.086436    0.084714    0.086522    0.117950  ...   0.078098   \n",
       "33      0.090749    0.087229    0.092767    0.063788  ...   0.080351   \n",
       "34      0.089170    0.083180    0.085976    0.054393  ...   0.081325   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "1376    0.894308    0.890872    0.888134    0.030330  ...   0.981312   \n",
       "1377    0.911559    0.907987    0.909174    0.023040  ...   0.976869   \n",
       "1378    0.915993    0.917740    0.915540    0.010876  ...   0.988678   \n",
       "1379    0.931726    0.927862    0.928515    0.016342  ...   0.984356   \n",
       "1380    0.933001    0.927494    0.920027    0.012977  ...   0.975347   \n",
       "\n",
       "      var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)   var2(t)  \\\n",
       "30     0.083338   0.081033   0.081004   0.023681  0.080168  0.081759   \n",
       "31     0.081759   0.079745   0.079064   0.014299  0.078098  0.079998   \n",
       "32     0.079998   0.081278   0.081671   0.004965  0.080351  0.081152   \n",
       "33     0.081152   0.082628   0.083308   0.007174  0.081325  0.082792   \n",
       "34     0.082792   0.084100   0.084884   0.008763  0.085342  0.088744   \n",
       "...         ...        ...        ...        ...       ...       ...   \n",
       "1376   0.981534   0.976322   0.977324   0.020729  0.976869  0.985118   \n",
       "1377   0.985118   0.986137   0.984903   0.012815  0.988678  0.986928   \n",
       "1378   0.986928   0.992841   0.985388   0.012168  0.984356  0.984511   \n",
       "1379   0.984511   0.991044   0.981204   0.007928  0.975347  0.978740   \n",
       "1380   0.978740   0.978653   0.979628   0.011643  0.975590  0.976918   \n",
       "\n",
       "       var3(t)   var4(t)   var5(t)  \n",
       "30    0.079745  0.079064  0.014299  \n",
       "31    0.081278  0.081671  0.004965  \n",
       "32    0.082628  0.083308  0.007174  \n",
       "33    0.084100  0.084884  0.008763  \n",
       "34    0.088578  0.087552  0.020643  \n",
       "...        ...       ...       ...  \n",
       "1376  0.986137  0.984903  0.012815  \n",
       "1377  0.992841  0.985388  0.012168  \n",
       "1378  0.991044  0.981204  0.007928  \n",
       "1379  0.978653  0.979628  0.011643  \n",
       "1380  0.983990  0.974535  0.008959  \n",
       "\n",
       "[1351 rows x 155 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_to_supervised(dataSc, n_in=30, n_out=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splitSequence import split_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.145909\n",
       "1       0.112308\n",
       "2       0.088447\n",
       "3       0.080898\n",
       "4       0.090516\n",
       "          ...   \n",
       "1376    0.976869\n",
       "1377    0.988678\n",
       "1378    0.984356\n",
       "1379    0.975347\n",
       "1380    0.975590\n",
       "Name: Open, Length: 1381, dtype: float64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(dataSc.columns)\n",
    "dataSc['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-2852e5e0fdc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataSc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "split_sequence(np.array(dataSc['Open']), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 30\n",
    "X = [(split_sequence(dataSc[col], n_steps)) for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataSc\n",
    "input_cols = df.columns\n",
    "# Put your inputs into a single list\n",
    "df['single_input_vector'] = df[input_cols].apply(tuple, axis=1).apply(list)\n",
    "# Double-encapsulate list so that you can sum it in the next step and keep time steps as separate elements\n",
    "df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\n",
    "# Use .cumsum() to include previous row vectors in the current row list of vectors\n",
    "df['cumulative_input_vectors'] = df.single_input_vector.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>single_input_vector</th>\n",
       "      <th>cumulative_input_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.124295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "      <td>[[0.11230825420014609, 0.11170503553422825, 0....</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>[[0.08844655466277088, 0.09305715847658388, 0....</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>[[0.08089846603360115, 0.0864362509870619, 0.0...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>[[0.09051619186754323, 0.0907489521958331, 0.0...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close    Volume  \\\n",
       "0  0.145909  0.162364  0.125445  0.124295  1.000000   \n",
       "1  0.112308  0.111705  0.094774  0.098830  0.284593   \n",
       "2  0.088447  0.093057  0.082137  0.080458  0.167031   \n",
       "3  0.080898  0.086436  0.084714  0.086522  0.117950   \n",
       "4  0.090516  0.090749  0.087229  0.092767  0.063788   \n",
       "\n",
       "                                 single_input_vector  \\\n",
       "0  [[0.1459094229364499, 0.16236408916965317, 0.1...   \n",
       "1  [[0.11230825420014609, 0.11170503553422825, 0....   \n",
       "2  [[0.08844655466277088, 0.09305715847658388, 0....   \n",
       "3  [[0.08089846603360115, 0.0864362509870619, 0.0...   \n",
       "4  [[0.09051619186754323, 0.0907489521958331, 0.0...   \n",
       "\n",
       "                            cumulative_input_vectors  \n",
       "0  [[0.1459094229364499, 0.16236408916965317, 0.1...  \n",
       "1  [[0.1459094229364499, 0.16236408916965317, 0.1...  \n",
       "2  [[0.1459094229364499, 0.16236408916965317, 0.1...  \n",
       "3  [[0.1459094229364499, 0.16236408916965317, 0.1...  \n",
       "4  [[0.1459094229364499, 0.16236408916965317, 0.1...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = 'Open'\n",
    "#df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)\n",
    "df['output_vector'] = df.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>single_input_vector</th>\n",
       "      <th>cumulative_input_vectors</th>\n",
       "      <th>output_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.124295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.145909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "      <td>[[0.11230825420014609, 0.11170503553422825, 0....</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.112308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>[[0.08844655466277088, 0.09305715847658388, 0....</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.088447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>[[0.08089846603360115, 0.0864362509870619, 0.0...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.080898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>[[0.09051619186754323, 0.0907489521958331, 0.0...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.090516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close    Volume  \\\n",
       "0  0.145909  0.162364  0.125445  0.124295  1.000000   \n",
       "1  0.112308  0.111705  0.094774  0.098830  0.284593   \n",
       "2  0.088447  0.093057  0.082137  0.080458  0.167031   \n",
       "3  0.080898  0.086436  0.084714  0.086522  0.117950   \n",
       "4  0.090516  0.090749  0.087229  0.092767  0.063788   \n",
       "\n",
       "                                 single_input_vector  \\\n",
       "0  [[0.1459094229364499, 0.16236408916965317, 0.1...   \n",
       "1  [[0.11230825420014609, 0.11170503553422825, 0....   \n",
       "2  [[0.08844655466277088, 0.09305715847658388, 0....   \n",
       "3  [[0.08089846603360115, 0.0864362509870619, 0.0...   \n",
       "4  [[0.09051619186754323, 0.0907489521958331, 0.0...   \n",
       "\n",
       "                            cumulative_input_vectors  output_vector  \n",
       "0  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.145909  \n",
       "1  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.112308  \n",
       "2  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.088447  \n",
       "3  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.080898  \n",
       "4  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.090516  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad your sequences so they are the same length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = df.cumulative_input_vectors.apply(len).max()\n",
    "# Save it as a list   \n",
    "padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()\n",
    "df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>single_input_vector</th>\n",
       "      <th>cumulative_input_vectors</th>\n",
       "      <th>output_vector</th>\n",
       "      <th>padded_input_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.124295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.145909</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.284593</td>\n",
       "      <td>[[0.11230825420014609, 0.11170503553422825, 0....</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.112308</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>[[0.08844655466277088, 0.09305715847658388, 0....</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.088447</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080898</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>[[0.08089846603360115, 0.0864362509870619, 0.0...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.080898</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>[[0.09051619186754323, 0.0907489521958331, 0.0...</td>\n",
       "      <td>[[0.1459094229364499, 0.16236408916965317, 0.1...</td>\n",
       "      <td>0.090516</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close    Volume  \\\n",
       "0  0.145909  0.162364  0.125445  0.124295  1.000000   \n",
       "1  0.112308  0.111705  0.094774  0.098830  0.284593   \n",
       "2  0.088447  0.093057  0.082137  0.080458  0.167031   \n",
       "3  0.080898  0.086436  0.084714  0.086522  0.117950   \n",
       "4  0.090516  0.090749  0.087229  0.092767  0.063788   \n",
       "\n",
       "                                 single_input_vector  \\\n",
       "0  [[0.1459094229364499, 0.16236408916965317, 0.1...   \n",
       "1  [[0.11230825420014609, 0.11170503553422825, 0....   \n",
       "2  [[0.08844655466277088, 0.09305715847658388, 0....   \n",
       "3  [[0.08089846603360115, 0.0864362509870619, 0.0...   \n",
       "4  [[0.09051619186754323, 0.0907489521958331, 0.0...   \n",
       "\n",
       "                            cumulative_input_vectors  output_vector  \\\n",
       "0  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.145909   \n",
       "1  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.112308   \n",
       "2  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.088447   \n",
       "3  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.080898   \n",
       "4  [[0.1459094229364499, 0.16236408916965317, 0.1...       0.090516   \n",
       "\n",
       "                                padded_input_vectors  \n",
       "0  [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...  \n",
       "1  [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...  \n",
       "3  [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...  \n",
       "4  [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0...  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1381 into shape (1381,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-bf782a9ac1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use hstack to and reshape to make the inputs a 3d vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1381 into shape (1381,4)"
     ]
    }
   ],
   "source": [
    "# Extract your training data\n",
    "X_train_init = np.asarray(df.padded_input_vectors)\n",
    "# Use hstack to and reshape to make the inputs a 3d vector\n",
    "X_train = np.hstack(X_train_init).reshape(len(df),max_sequence_length,len(input_cols))\n",
    "y_train = np.hstack(np.asarray(df.output_vector)).reshape(len(df),len(output_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One more attempt, with split_sequence\n",
    "\n",
    "Important to change into numpy array before operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = dataSc.iloc[:,:4]\n",
    "print(data.columns)\n",
    "dataNP = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(dataNP[:,0], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1351, 30)\n",
      "(1351,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(50, activation='elu', input_shape=(input_shape)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(50, activation='elu', input_shape=(input_shape)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1351/1351 [==============================] - 0s 340us/step - loss: 0.0190\n",
      "Epoch 2/10\n",
      "1351/1351 [==============================] - 0s 80us/step - loss: 6.9871e-04\n",
      "Epoch 3/10\n",
      "1351/1351 [==============================] - 0s 70us/step - loss: 5.9684e-04\n",
      "Epoch 4/10\n",
      "1351/1351 [==============================] - 0s 84us/step - loss: 5.5118e-04\n",
      "Epoch 5/10\n",
      "1351/1351 [==============================] - 0s 81us/step - loss: 5.1227e-04\n",
      "Epoch 6/10\n",
      "1351/1351 [==============================] - 0s 83us/step - loss: 5.2140e-04\n",
      "Epoch 7/10\n",
      "1351/1351 [==============================] - 0s 86us/step - loss: 4.2736e-04\n",
      "Epoch 8/10\n",
      "1351/1351 [==============================] - 0s 82us/step - loss: 4.0592e-04\n",
      "Epoch 9/10\n",
      "1351/1351 [==============================] - 0s 84us/step - loss: 3.9384e-04\n",
      "Epoch 10/10\n",
      "1351/1351 [==============================] - 0s 92us/step - loss: 3.7040e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f387ad54f90>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= X, y=y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351,)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x= X)\n",
    "y.shape\n",
    "y_pred[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f38973990d0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXxV9Z34/9fnnLvmZg9JWBLZRCRYUIKI0FqsbUcr6lhwAXGhiiDt9NeOtdrpULVMZ0TsdLQVWTqiiEUs6Fdr69KxMu2AiMSFCorKZqJA9uXu95zz+f1xc48JQUUJEML7+Xj4IPfek3sPiO98fH/en/dbaa0RQghx/DOO9Q0IIYToHhLQhRCil5CALoQQvYQEdCGE6CUkoAshRC/hOVYf3KdPHz1o0KBj9fFCCHFcqqqqqtdaFx/stWMW0AcNGsTmzZuP1ccLIcRxSSm155Nek5SLEEL0EhLQhRCil5CALoQQvYQEdCGE6CUkoAshRC8hAV0IIXoJCehCCNFLSEAXQohe4pgdLBJCiN7AshxqwwlStoPXNCjJ9uPxHJu18mcGdKXUg8BkoFZrfdpBXlfAvcC3gChwndb6te6+USGE6Gksy+Gd/W3MWVlFTVOMsoIgD8yopF+uH42iKOTDMNRRu59D+THyEHD+p7x+ATCs/Z8bgQcO/7aEEKLnqw0n3GAOUNMU46aVVTRFU1y6aD1v72vFspyjdj+fGdC11n8FGj/lkkuAFTptI5CvlOrXXTcohBA9Vcp23GCeUdMUwzQUNU0xZj9SxYctsaMW1Lsj0TMAqO7wuKb9uS6UUjcqpTYrpTbX1dV1w0cLIcSx4zUNygqCnZ4rKwhiO+lZzTVNMeraEnzYEmN/S/prxzlyc5yPauZea71Uaz1Waz22uPig3R+FEOKYchydDsJN0c8MwCXZfh6YUekG9bKCIIuuGsOyv+50HzdEktS1JXijpoVLF61n+/62IxbUu6PK5UOgvMPjsvbnhBDiuOI4mu3725i1YrO7yblkRiXDikO0JGySlo3PY7qbnR6PQXlBgIdmjsNU6RX7Iy/v4vGqGsoKgiyYMoqHN+xiSmU5+UEvNU0xZq3YzJNzJ1Kc4+/2+++OgP408D2l1GPAWUCL1npvN7yvEEIcVQ2RpBvMIZ0yuffFd/n+ead0qmRZPKOSkhw/hVk+cgM+9jYnuO6RzUwYUsScSUP5xsh+NESSPLxhF9dOGOwG9cx7Ji37iNz/oZQtrgImAX2UUjXA7YAXQGu9GPgT6ZLF90mXLc48IncqhBCfk+NoGiJJkpZN0GdiOZqU5XRaZWeuSVg2tqO7bHJOqSzvUskyZ2UV8y85jT45fsoLApTk+bjnstH0zQ3gNRV98wJ4TYMpleVuUL/n+e1AOg3j85hH5Pf7mQFdaz3tM17XwHe77Y6EEKIbdEyfFGf7+fH5w7llzRZ3lf3QzDMJ+T04jiZpO3gMhWkoygqCnYJ6Uch30EqWLJ/JTSureGjmODyG4sqlG1l943iuWLqRM8rzmTNpKCU5fm67YAR3Pfs2r1c3U1YQZNk1YykK+Y7I71lOigoheqWO6ZN5kyvcYA5QnO2nri3B71/9gMmjB/Drv7znpkYWz6jslF4pDPm6BPmygiDNsRQ1TTEMBbvqI+5zZQVBXq9uZvYjVQB8s6KEOy4+jdsv0p3+z+BIkF4uQoheKWnZbhDObEhmzJk0lOXrdzHtrEHc9OhrTKks59a1W3hhWy1eEx694SzWzDmbeZMrWL1pT5dKlgVTRrF43Q63RPG+F99jyYxK1lZVs2DKqE7X/vAbw+mbG2BAQRbFOf4jenJUVuhCiF7J5zHdlXVm5dwxwE+pLMdqz5l3DPjNUYvCkCIv6KU4x8+IfrkEvIrfTDuDvCwvu+uj3PP8durCCR64qpJlf91JXThBv/wAv7h0FI7j8Pjss9H6yK/IDyQrdCFEr1QU8rHsmrHpqpR1O1g49eOVczRpUxTyYSo6pUqA9lRKnJkPvco7+9r4t2e20hhJYhiKx17ZQ1lBkF9ePppVs8az7p39bNjZwLJrxpIf9FGc46c0L0j//OBRWZEfSKX3NI++sWPH6s2bNx+TzxZCnBgcR7OvNc5HzTFStoPtaLymwYCCAClLUx9OApplf9vJtRMGc+vaLRRn+1kw9Us0hJMsX/9x2eF3zz2ZwpAfR2t8poHPq4gnnaO+CldKVWmtxx70NQnoQoje7GCHhVZ8ZxyrN+3h25XlxFM2sZRD//wACoXWGttx8HtNbAdAk7Q14bhFfpaXfjl+fL5jl62WgC6EOKF1rEf3mgag2d+a4Nd/eY+ZEwfTLy+IUhCOWxRme0la2i1jtByN7aQfl2T78XqPTA35ofq0gC6bokKIXs8wVKej9pblYDmaf/lWBUqBaSj8HgOPoXCc9GNba7QDsZTNzroIp5flHfNg/lkkoAshTjgej4GpFNv3t3Jq3xySlsPP/7CVF7bVUlYQZOHUUQBMW/YKkN44fXLuxGN5y4dEAroQ4oRkGAbzn9nGhCFF3HDOYKaNG8j1Xx5CNGnTJ8fPwufeATjipzu7kwR0IcQJqSjkY8nVle6Jzhu/OhSvqbAdTcq2mVJZzm0XjGBPQxT/MZoR+nlJQBdCnJAMQzG8JIdHbziLurYEO+rCrK2qdhtp1YUTzJtcwexHqtyUy5Foedudjo8fO0IIcQR4PAbZgXQXxpNLspk2bqAbzO+fPobF63YAR7blbXeSFboQ4oTlOJqWqIXWmgXPvs2UynJ+euEICkM+Fq/bwevVzUA6j+71GNS1JboMuehJJKALIXq1TA264zjYmk49VhoiSa55cBPF2X7mTBpKftCL5WgcrdmwswH4eFM0HLe45sFN7uGkZdeMZXhpTo8K6nKwSAjRa2VOif7qz9vdo/0dA3JuwMPEBS91+b5XfvI1DMNwV+OmARf/Zn2XFrrHIq/+aQeLJIcuhOi16sMJZq3Y7LbH7Th1aNaKzSil3KZcGWUFQQzDoDjH7zbYiiXtgw656Gl5dQnoQoheyXE0sZTdpT1uRk1TDFPhdmSET645z7Ti7ehIjpL7oiSHLoToleojCRytO7XHPTBlYhgGw0tzeHLuxE/d7My04u3Y4KsnHjaSHLoQ4rjUseHWgYHYcTQfNEbZ25IO4Jk2uAfm0D/Ppuanfd7RJM25hBA9luNo6iMJ4ikbUymCPpP84KcHy4O1xF08o5J++X4Kgn4aIkl21UdYtWkPc889mWnjBpIb8LgDnX2mom9e8HMF5AMbfPVEkkMXQhw1luVQ2xqnpinKnoYI+1vi1DRH2fphK3ub47y7P0x1Y5Sd9WEsy/nE96mPJNxgDul8+JyVVWypbmX7/jaSls19L77Hd88dxqKX3idpOyQsB0PBqld24/WYParcsLvICl0IccQ5jqYlnqA+nKK+LcEtaz5OfTw080yCvs6bi02RFD4zRsBrorVGKZWeOKQ1Ib9JNHHwqpMsn8msFZt5fPbZ1IUTPLpxD7ddMILGSJKGSJKlf93BD78xvMflvruLBHQhxBGVSY94TYOaxhjznnrLDcbF2X7qOgT4b1aUcNsFI9x+5NGkRXMsRSxpu9csv+5MgINucqbngX5cvTJrxWbeqw3z/fOGMbw0h3+79Ev0CR3dOZ9Hk6RchBBHVEMkyawVmzEUZPnMTkF4zqShbqA+ozyfaycM5poHN/HVheu4+r83EU7YxFOOew2k3+O+F9/j/uljOpUbLpgyisXrdnSpXvnN9DM4bUAeJxVmUZIT6LXBHGSFLoToRgerBEla6fSI7WiiSbvTyrpjfficSUO7HP6Zs7KKh2ae2emHQHMs5aZTVl5/Fo7W7GmIuk21MuWEx8MmZneTFboQoltkUiuXLlrPxAUvcemi9W6qpawgyLK/7nSnAWVW1pkAD3zy4R+j82nOxet2sHDqKDbsbOCHq9+gIZxkWEk29047nSfmTuhx/VWOJgnoQohukUmtHHi8XmvN4hmVbNjZwHN/38ugPiFWzRrPuh9NYnCfLJZcXdnp8E9HZQVBPIbq9EOgLpygNDfAE3Mn8JvpZzCoT4j++UFOKgz1+pTKZ5GDRUKIbvFhU/Sgja7+95ZJGAr2NETpmxcg5PeQSKUrVvweA59HEUs6+DyKxnCK2Sur3AqYJTMqKc7xAZkqFwh4jV69sflZDvtgkVLqfOBewAR+q7W+64DXTwIeBvLbr7lNa/2nw7prIcRxJdPv5MDKE4+hiKUcbnvi79Q0xVhydSXzn9lGTVOMVbPOIstn0hhJkeUzKcr2sfrG8ViOxmMosgMGOf4TN3h/Xp+ZclFKmcD9wAVABTBNKVVxwGX/CjyutT4DuBJY1N03KoTo2TL9Tg5sdFWS7cfnUSy6Kl2VksmBlxUEufu57e73+zwGoNBovGb6xKgE88/nUFbo44D3tdY7AZRSjwGXANs6XKOB3Pav84CPuvMmhRA9n2GoT2x01T83SMhnuqvvgMdwv/Z7DEpyAjTHUu5cz59cMILLl2zskUMkerJD2RQdAFR3eFzT/lxHdwAzlFI1wJ+Af+qWuxNCHFcypYKZPuKZQOzxGBRlBxhQkIXHUDz+ajWOBkdrUrbmofU7ueDevzH/mW3MnDiYfa1xd1O1PpI4xr+r40d31aFPAx7SWv9SKXU28IhS6jStdadmDEqpG4EbAU466aRu+mghRE91YOOtkN/EdjSrq2r4y/Y6bv7mKQwsyuKyMwdy/pf60xxNEfSZ3Pl0OgFQ0xQjnvrkni6is0NZoX8IlHd4XNb+XEfXA48DaK1fBgJAnwPfSGu9VGs9Vms9tri4+IvdsRCiR3McTWMkwf6WGG/va+XbizZwzt3ruGLpRhojKf7tj9tYMGUUdeEEM/57E/Of2YahoLC9v8qdT2/rNJzZlGzLITuUFfqrwDCl1GDSgfxKYPoB13wAnAc8pJQaQTqg13XnjQohjq1UyqY2nMByNCGfScJy3Hx4eg2tMZVBazxFXVuCeMrp1LelpilGYyTJC9tqqWtLMm9yBcNKsnmvNszNj7/Jj88fTsBrUBdOp1gyh5AObNwlPtlnrtC11hbwPeB54G3S1SxblVI/V0pd3H7ZzcAspdSbwCrgOn2sCtyFEN0ulbJ5pzbMFUs3cv9f3uejljhXLN3IDx57g531EW5/6i121kXZ+lEr1Y0xblmzpUvfFkgfPiorCPJ6dTOzH6nivdow859Jr8jvfm47QZ/J/EtOY/WN45l/yWmU5gbID/bOzohHwiGdFNVa/0lrfYrWeqjW+hftz/1Ma/10+9fbtNYTtdajtdana61fOJI3LYQ4umrDCW5qP/Az65whzH30tXSvlfbmWpkhzFk+0w3kBzv5ubaq2i1fzDxePKPSDfKLXnqfocUhygqCnDYgj0FFIalw+RykOZcQ4hNlmm1ZjnZX26ahujTXyvzaHEvha+/dsnjdDn552Whu/v2b7snPmRMHU5Dl5Ym5E0hZDj6PSUHQ+5kzPcWhkYAuhDioTLOtX/15Oz+7aKR7CtR2tPt1ZhWe+XXxuh3cfnEFC6eO4pY1W7jr2Xe457LR9MsL4DE+ebzcidYV8UiRXi5CiIOqa0tw6aL1zJtcwd6mCJWD+3DTyiomDClixtkDmfvoaxRn+/nx+cM7DWEuzvbzL98aQb+8AA6agNc8oXuvdLdP6+UiAV0IcVCZZlurbxzPFUs38vwPvkyWz4uju1a5WI7GaR8Vp7Um4PVI6uQI+bSALu1zhRBdWJaDUqpTOuW2tW/xQWOUq377CrNWVKFJH9tP2unTng3hJPGUTb/cYKdTouLokRW6EKITy3LY3RjBdhwSluY3f3mP6788hJt//ybF2X6+f94wTirKIpKw6JvrJ2lpbJ3ujliaE8DjkXXikXTY7XOFEL1fx/Fx1Y3pKpZVm/bws4tGEklYrL5xPEnbwWsYGAbUtdnMfuQ1d+ybNNE69uRHqRAnKMfRtMTSR/T3tcTYtreVnz65BcvRbj35C9tqQWsSlsOft+7FUIp9rXH2NEQB+M8rTueJm07ssW89iazQhTgBOY5mf1uMcMKmvsMx/XmTKzANRTRpA+nj99VNMQpDXs4ZXkrKdijJDWA7Dl7ToDTbj9crR/N7ClmhC9FDOY6mri3Bh01R6toSWJbT6bHjHPr+14HvVR9JYNlQc8Ax/fygF0PBgIIAhSEvC6eOYvn6XcRSDg3hJKZSpCwHj2HQNycgwbyHkRW6ED1Q5lBPZuhyWUGQxTMque/Fd6lrS/L984YxuE+ILP9n13gf7L1WXn8WKLoc02+OpfjL+n1MGz+QgNekJNfgZxeNxFCATk+ykdOcPZcEdCF6oIZI0g3AkO5UOGdlFQunjsLRcOvaLW5wPtiGpGU51IUT7ZuYilkrNlOc7Wfe5Ar65wVQCgyVTq1kTngumDKKhzfs4vovD2HVxj1MHXsSlq3xmgbKgNLcoATxHk5SLkL0QEnL7tSp8IzyfO769pfonx+kf36AhVNHcUZ5vjvVpyGS/Ph7kxbv7G/jofU7SVoOKUdTnO3nR/8wnPnPbKMlluIXf9yGUpqywnSL2rpwgnue3860cQPpnx9g2lkDMQ2FzzTI8huU5kgwPx7ICl2IHsjnMflmRQlTKsspyfGTH/TyH8++zQvbat0+4f8x5TTq25J4TYOkZeM4Op0rjyT5wxs1XDh6AAuff4d5k0fy/fOGuav6vnkBXthWS37Qx60XDCfH7+GxG8djO+lacoDGWIo+2T765UkgP57ICl2IY+zADUvH0eQHPPz0wgqKQj5q2xL8x7Nvc+2Ewe6qfPn6XSQtzW1P/J0rlm7kiqUbeXtfKw2R9ACKqWNPYu6jrzGlspx9LXEG9cn6uFti+wnQx6tqWPDsdlK2xm4/uv9BY5Q7/7CVpGUT9JkSzI8zEtCFOMo6BvDatji7GyJcumg9Exe8xKWL1rN9fxt7mtJH7Kcufpn5z2zj2gmDeXjDLuZMGgrAlMpytyc5pHPssx+pIuVoTEO5LW7zg15+v7kaoz2IA+xrjbNw6ig3qK98eRfe9jlvxTl+vvPlIRRl+2WwxHFIUi5CHEUHqzhZOHUUE4YUcV5FKflBL/ta4mT7PZ2C9a1rtzBvcgX5QS8ARSFfl2lAmda2Po/C5zHcqpULvtSPX/xxG/dPH8N3f/cadz+3nTsurmD+JaeR5TOJJm1a4ymaoxb98gIMKQ5Jd8TjlKzQhTiKDla9snz9Lq4aP5D5z2zjrmffAaBPjo+V14/jjPJ897qikM8tLywM+bpMAyorCKI1JCyHoFfxwIxK1lZVM7Aoixe21fLoxj2s+M44fnrhCKLJdEqlOMeP11T85wvvkuP3MCAvSElOQIL5cUoCuhBH0YHVK5BOn3z3d+ne4rdfXAFAbWuClK25/eIKzijPp6wg3cFwVFkuq2aNx3IcHmgf3QbpYH7/9DGsemU3fo9BPKXJD3qYf8lpBLyGm165+fE3iadsSnMDAOxvjRPwmtx2wQgGFEhjreOdpFyEOIp8HtOd9pORSZ8snDqKWNJm3lNvuemY+6efwX9deToAHkNhKoOaliiFIR+RRIKFU0dRmhvANBS/27ibC0b1Z19Lgn9a9bo7fMJjGO4Eoderm7ntib/zm+lnYNkOAa9JXtDLzY+/yW+mn0F+1rH6kxHdQX4cC3EUFYV8LLtmbKeVdUmOn7KCIH1zA9yyZosb7Iuz/YT8pluFEks5NEUT5GV5WPK/O/jR79/E0RBJWLTGUsw4ezAFWT7+adXrnQY4O1pz93PbuevbX+KlH32V+Zecxp1Pb+O2J/5OwnL48Zot1IUT+DxyjP94Jyt0IY4iw1AML83hybkTcZz0EImU7fDoDWfh9xj81xWnk5/lxVTpjc1I0uI7D21yV+yLrhqDqWDOpKG8Vxvm1rVbWH7dmdQ0xYinHAqzP94s7Ti4uS6cYMZ/b+LyyjLmnnsyv7x8NHsaotzz/Ha3/W1RSKpajneyQhfiKDMMRVHIRyRps6MuzBVLN/KDx95gV32EH6x+g6//51+5+sFNfNAYJZa0Kc5OD1CuaYox99HXyA16aYwkmTNpKDVNMcIJi/LCAMU5fnym4a7+Ow5uXjDl4zLFf//TNgJeg1NKs7l32hk8MVfa3/YWMrFIiGOgri3BWx+2uPnyzLxO0wCtwdYaQym8hkIpSNkaw4AdtRGGFIf4+4et9M8LUB9OMrxvNo2RFHPaBzhfO2EQs1dWuTn0W9ZscScNDeoTInQIDb1EzyUTi4ToQRxHE0tZZPlMirP9LLtmLAGvicdU6eP7Oj2jMxxPkRPwYBiwauMeLhw9gL+9W0tBqIxkKoVSQbeH+fxntlHTFOO8ilJygh4eveEs6toSpGyHey4bTWmun5Zoirygh8KQ/1j/EYgjRFIuQhxFluWwvzWGQmEoxb9861RmrdjMDx57g931Ee78w1Y+aIxx7YObuOT+9Vzz4CaSlsPVEwaTtByuOnswT79ew6jyQuasrHJPg3bMm7+9t42X3t5HaW6A0twARSEfj72yB6/HkNOfvZwEdCGOEsfRfNQaw3I0XhP65gX44eNvdqpImVJZ7jbRgnSlS0M4yZVLNzJ18ctMX7aRK8YNpK4t4V6TyZVnvl5bVc2wvnnMf2Yr79WGaYmlmD5+EMNLJE/e20lAF+IIcRxNYyTds+WDxgj72+I4WhNNWkSTDpbjdKlI6bjaBtxA3/FkaWMkSUMk6Qbxjpuei9ftYObEdN+XKZXlFIV8FIZ8hHymHBo6Aci/YSGOAMty+LA5RlM0xbv7w/x/q97g9qfeQqHwezzsaYjyYXspItBpYlDHI/0HBnhItw9YW1XN/dPHUFYQ5PXqZh7esIsV3xnHHRePpKwgyDVnDyI/6KUhkuSuZ99GIyvzE4FsigrRzRxHs722jdmPVLn147+ZfgamUuxtiVOc7efkkmwCXoMlV1cy+5EqFq/b4c7vXDBllJt2yUwU6hjU11ZV891zh/GnLR+y4jvj3BX7Xc++zQ+/PpyUnW6r23GikdSYnxgOqWxRKXU+cC9gAr/VWt91kGsuB+4gPXbwTa319E97TylbFL1VXVuCSxet7xSEfz/7bEC7OfNMl8XywiCOVqA1Xo+B42gMBY6mvXOiQUM4yeyVVR3aAYwh5Dfxe0w8Jmit0Fq7sz4hvYpPWrbM/+yFDqtsUSllAvcD3wBqgFeVUk9rrbd1uGYY8BNgota6SSlV0j23LsTxxXE08ZTVJU3SJ9vH1Q9u6pQLv2XNFlbNGs/0ZRt5bNZ4Llv8MjVNMZZcne6SeO2Ewdy6Nl1Dfs9lo+mXF8BUCgfNBw1RVry8m19cOorinK5liAd7TvR+h5JyGQe8r7XeCaCUegy4BNjW4ZpZwP1a6yYArXVtd9+oED2Z42jqIwliSRvTUF3SJLbm4P3LtaamKYZpKreB1uJ1O/jx+cNZvn4X8yZX0Dc3QEHIR1MkwXd/97qkUsQnOpSAPgCo7vC4BjjrgGtOAVBKrSedlrlDa/3cgW+klLoRuBHgpJNO+iL3K0SPc+DQim9WlLDoqjHuRKGygiD+9oETHYN6WUHQHQdX2xqnT7bPHTphKMW/Tq7AcdIThvp7Dfy5AR67cTyOhoDXkNOeoovu2hT1AMOASUAZ8Fel1Je01s0dL9JaLwWWQjqH3k2fLcQxdeDQihe2pf8Hdfl1Z9IYSdIcS/HrF99j8YxK9zBQJoduOTYPzKjk1y++yz9/8xQG9wmhFBhK0RhJcP9L7/NPXxvG7vooBSEvgwpDUn4oPtGhBPQPgfIOj8van+uoBnhFa50Cdiml3iUd4F/tlrsUogc72NCKF7bVcv2Xh3DF0o1AejV+6ZgBPHrDWViOxmcaeE2FZTv0z/Ny+0UjUem9UQyVTtEUZPn42eSRNEWTNEaTLPvbjk/MmQsBh1aH/iowTCk1WCnlA64Enj7gmv9HenWOUqoP6RTMzm68TyF6rMzQio7KCoJEk7b79S8vG83y9bt4Z18b5/3yf5m2bCPv14a5ctkrtMYt7vzDVmrbEry7P8wHjTHe2x8mlrL5p1Wvc9Fv1jP7kSpe2FZL0rKPxW9RHCc+M6BrrS3ge8DzwNvA41rrrUqpnyulLm6/7HmgQSm1DXgJuEVr3XCkblqInsBxNHVtCRSaJQeMg1tydSWn9svhxX/+Knd9+0v89//tZObEwSxetyP9+oxKTirK4p7LRgMw6ytDWPTS+yRtB9NQDCkO8URVNa9Xf5y1LCsIyhAK8amkfa4Qn4PjaBoiSRzHoT6c5N4X3+XaCYP56/b9TDtrEJrMnE6D4mw/job6cILiHD+moUhaDk2RJLGUjdc0KAz5WL1pD98a1Z+2uEXAa1KS46dfboD36yNubj5T1SJ9y8Wn1aFLQBcnpExgPvDwTab80HYcHCd9uMdjKFDgNQ1q2xLMfqTKbVk7b3KFWzNemhvguuWb3NdWzRpPwnK4bvkmdwC0AhojKfKzvOQEvAS9Bl7TwGMqYsmu9yIHhMSBPi2gy3a5OOFkygwvXbSeiQte4tJF69m+vw3Lcti+r41/ffLv7KyLcsXSjZyzcB2XL91IdWOMD5ti7nH+js20Mh0SDUWn1xytsR2bRVeNoS6c4M6nt5G0NCeXZFMU8pEb9NAvL0hJboDCkJ8BBVkU53xcimgYiuKcrs8L8Umkl4s44RxYZljTFONXf97O7ReNJJK0uOUfTmXh8+9QnO1n4dRR9M0N4DEVlqO7tKxtjqUoCqXneNqO7tRg6/6/vM+sc4ZgKodVs8bjaI1pKF7f08D4oSVSrSK6nazQxQnnwDLDM8rzuXbCYK5o7zk+86FXmXvuyfz8kpEAXP3gJrbtbWN3fbRLy9q1VdUUhnzpHPdfd7LoqjGsrapmwZRRbNjZwHN/30tu0EvKdkhaDo9s2MXJpXlywlMcEbJCF73agXnogqAXpTofzZ8zaWinoRI1TTGaIikAd+ZnftDLXc++43ZCzLSs/emFFRgKlsyoZPbKKgB+fP4IsnwGq2aNpzmWYl9LnD45PpSC8UOL8bcfDJIcuehuEtBFr3XgkfyygiCLZ1SyeVc9908fw3d/lz6an0mZdJTlS5cHdkyx1IUT3GN2lEsAACAASURBVPP8duZNriA/6EUDHhMawin++OaHLL/uTDymwmsaPLx+F0v+tts9EdoSS3Hn09t4vbqZsoIgT8ydQEM4KVUsoltJlYvolRxHs681zkfNMRoiSV7ctp/zKkrpmxsgL+hl1Su7GTOoiKKQj755Aa5curFTUF9+3ZnAxyv0M8rz+dE/DHdX8pnDQnlZHmwbcoNeHJ2uiNFoklb6vyuvaVAfjvPzP7zdqab8rz+exPRlr3Tp7fLk3ImSWxef6rDa5wpxvDlYs6zvfW2Y2yzrmxUl3HbBCFpiKWrbEvx5694uzbQKQl5M9XEHxEyK5dEbzsJ2NHsaotz17DsU5/i47YIR2FrjMxSW1nzUnB5iEfAaBH0m05a90SVwG6iDdl+Uk6DicEhAF73OgVUsUyrL3WCd2QC95sFNTBhSxI1fHcqpfXMIeAwenz2elK3Z2xLnzqe3UZzj486LR7L6xvFYjsbRmtZYinjKYWhJiHsuH43HUPg8Bo2RJNubYqytqmbmxME4aAwDcnyeLk25Fs+oZG9L/KDdF+UkqDgcEtBFr3NgFUvHuZyZDdAJQ4qYcfZArlu+yQ20i64awx/f/JCLzyhj8YwxGIZBnt9ke12EX7/4rjt0uTQvQMqyWfDcO+4QiszK/6cXVqAUNIaTNEdSaK2478V33bx7cyyFUvDvf3q706i5TDsAqX4Rh0MCuuh1Ms2yDqwZ73joZ9Y5Q5j50KudKlvmPvoay687k5kPvcqTcydSFPLxUUuMm9pX15m2uGUFQX436yx+dtFIN/eeWflf9dtX3AD9wFVjsGyHF7bVut8LsOTqyi4brNGkTb/8gGyIisMideii1ykK+Vh2zVi3ZnxtVTWL25tnZYK7aRw8h515PmnZ7SWFzkGvs2zNvpb4p5Y+3vToa+70oo7WVlW7QX32I1Xc/Ps36ZsXID8oq3NxeGSFLnodw1AML83hybkTO9WfPzl3Io7jsOTqShzNQXPYmdOePo9J0rLdxwe7riGS7LLy76imKYbHUCy7Zmyn8sQffmM4w4qzO92f1KCL7iABXfRapgEKiCYtEpaNzzQoCvkpzgnQGk/ywIxKN52SyaGv2fyBO6uzPpJgzYZdXSpgHriqkmV/3UlzLMmSqyuZ/UhVp7RORllBEMMwuvxwyQRvKU8U3U3q0MUR110nIjOdEOMpG1Mpgj6T/GDX93Icze6GCLGkRVvCpjTHj9djYLRPBMryGcRSmqKgl/poEqu9o6LfY6BR7v01hOO8uz/Munf2M3XsSZhG+tDQ/3uthtVVNSyZUcnw0hyaYql0O91I0m3eJQeFxJEidejimDnYac0vEugO9j4Lp46iNDfAoKJQp/dqiCRpCCcBzY9+/6Z7/YIpo3h4wy6+f94p7KprZXBxbqdywiUzKumXHwDAshxa4xZ3P7edX16eHkJR25ZAa83ZJ/fhwtH9KQx58XgMd6VdnBOQNIo4pmSFLo6ourYEly5af9gnIhsjCd6sbiHLZ9IcS/Hitv18u7KMvrkBAl4DrcHRGp/HxHEcUrbDe7URygoC+L0eDDQahVIaR6dX6pmKlI73Nf+S0+iblz5Nun1fG/OeesvtZd4USZHlM4kmbQYWZXX5QSLE0SD90MUxc7AByp/3RKTjaPY2x1m1aY+bq752wiAe/L+d1DRFiSRt3tnXxvd+9zo/fXILttY0xyz21LcRT2n+7Zmt7GmMMf+ZrexpiPFRc5y6tsRB7yvLZzJrxWZStsN9L77Hgimj3F7mACW5AUYOyJVgLnokSbmII+rAmnD4/CciGyIfj3q7de2WTlOCOh7M+c30M0ikHLbvC7Nq0x7mTR7JtGUbmTe5wv2+W9du4aGZZ7KjLnLQ+2qOpdzqlIPViod8JiU5gW79MxKiu8gKXRxRB9aEZ3Lon+dEZNKy3alAxdl+hhaH3McHtry9+fdvkuUzmVJZTsp2ukwXqmmKYSrl9izveF/3Tx/jDnEO+U0Wz+hcK16c46cwS2rFRc8lK3RxRB2sJvzzbhZmvqc428+P/mE41Y2f3PK2pinmThE6cIJQ5td9rXFmThzM8vW7mDe5gqKQj8KQj8XrdlAXTrDsmrHkBnycWurl8dlnY9kOHtOgJNuPxyNrINFzyd9OccQd7mzMopCPkhw/3z9vGLeu3cJ9L75HUfuUoI6iSTvd/GrdDgpDPtZs/qDTBKHMr8vX70p3QRw3kPygF8vRBLwG3/vayTw++2yGFWdjGAqPx6B/fpCTikL0zw9KMBc9nvwNFT2eYSj65wUZ1CeLmqYYr1c388C6He5xfkinTMoLg+6R+sXrdnDh6AH88c0PueUfTuWkwiC3XzSSsoIg/zp5JEGvybDSbPKzvJTk+Hl4/S5sR3P5kpd5ry6M4xyb6i8hDoekXMRxweMxCPk97kbm41U1AKyaNZ79rXEaIknq2hIMKAjyyPXjMJUi4DW5ZsJgEpZDPOWwZvMHXHR6GV5Tke33uBugmZa3+1rTvVlmrdgsgybEcUlW6OK40Sfk77TBumFnAxpN0Gcy/5lt3P3cdmJJi5TtEEtZ7GuN8+ete/GaBqahmDr2JP7wRg2tsRRtiRS1rQnyg16mjRtIYcjH3c9tB2TQhDh+yQpdHBccR9McS1Kc7XMHTngNhcc0+Lf/2cZd3/4SffMCBDwGfq+J7WhMQ/GNkf1QCsDAY2q+ckoJXo/Bf76Q7m+eY3gYWJTF4nU73BFxMmhCHK8koIseL9ObpS2eIpq0uWVNunzxx+cPpzgn0KXf+Oobx3PF0o1d3mf9redy2xN/pzjbz5xJQ90NUUdrNuxsAL5YWaUQPYWkXESP1xBJsqchSmMkxS1r0rXncyYN5ZY1WzAVn1jt0lFZQZCgz2TZNWM71ZbnBb0MKgzx5NyJrL/1XJ6cO1EaaonjlqzQxVGX6b6YsGwUpFMiGnweg0jSxmMovB5FytIoBSlbk+VLp0AyteeZQ0L7WuPuIOfMidHCkJcHrhrDTR1a3i67Ziz5QR/5QZ+0shW91iEFdKXU+cC9gAn8Vmt91ydcNwVYA5yptZbOW6ILy3L4qCVGUzTd6CppOwS9Jqs37eHC0QNY+fIeNuxscOd7njO8FNNQxJLpTcpMlUvmkNDdz23n55eMZP4lp7mNswDys7w8MXcCKcvpcphJgrforT6z26JSygTeBb4B1ACvAtO01tsOuC4H+CPgA773WQFdui2eeFIpm/3hdAtajSIcT5ET8NAQTtInx0fSSh/wSdkardMr95ZYioIsLwnLIZKwuuTQM1/fesGp9MsLYBqKoM+gIPj5DzAJcTw43H7o44D3tdY729/sMeASYNsB180HFgC3HMa9il7Kshw+aoujHfB5FI6Gvnl+9rYkWLTufeaeezIpS5Of5aE+nOwUtOc++hqPXH8mxTl+HK1ZNWs8jtb4PQarbxxPYzRFts/kB4+9QV04wZNzJ0owFyekQ9kUHQBUd3hc0/6cSyk1BijXWv+xG+9N9CIt8SSt0RT//qdt1LYlsGyHREoz+5EqZk4cTCxpE05Y1DTFu2x81jTF+OfVW0hYNqBwdLokUaO593/e46aVVbxbG+b16mapIRcntMOuclFKGcB/AjcfwrU3KqU2K6U219XVHe5Hix7IcTR1bQk+bIpS15bAcTRW+0nNmx59jZkTB+M1FHtb4iTbuyH2zQ1wy5otZPlMt8EW0Gnw8uvVzfzz6i3YjsZyNO/tDzN35ets2NnAgimjWLxuByA15OLEdigB/UOgvMPjsvbnMnKA04B1SqndwHjgaaVUlxyP1nqp1nqs1npscXHxF79r0SNlxsRdumg9Exe8xE+f3MK+1hj72uJYjnaDd21bOqViGoqygiC21u5GZ8eSw8zGZ8br1c3srIuw4Nm3SdoOP7uoghXfGcfDG3bxenWz1JCLE96h5NBfBYYppQaTDuRXAtMzL2qtW4A+mcdKqXXAj6TK5cTQcQA04M78vPnrw7jyrJNIWg52+xDmTPDOrMJNQ7Fw6ijqw0m3S+LtF1e4ZYiL1+3oUpJYEPIy6ytD+OHj6Vmh36wo4V8vrOD2i0bKHE9xwjukmaJKqW8B/0W6bPFBrfUvlFI/BzZrrZ8+4Np1HEJAlyqX45vjaOojCaIJm131Ee578T3uuHgkdzy9lX+79DRKcvw4jiblaAwFHkOxvy1JJGERS9rMe+otrqgs44JR/WiKpAj4TG5aWUVxtp9/+dYI+uYFcLQm6DVJWI7bgGttVTW3XTCC7IDnoCWJQvR2n1blIkOixeeWSa1kVuOZ8W99cwPsb40T8BoopWgIJ1m+fhfXThhMv7wAsaRNYbaPSMKiri3BLWu28P1zh/LlYcWg0oObbUdjGAoF2Frz6Mu72bS7me+fN4zBfUJk+U36hKQkUZy4DrdsUYhOGiJJN5gDFGf7iSVt9rXEaYqmKC/Moroxyryn3nLneE4YUsSNXx1CbWscgJDfw2Pt5YdmewBPaY3u8Blaa648ayDTxw8i6DXpky2BXIhPI71cxOeWtOxO49/mTBrK8vW7yMvykuUzMdTH4+AylSqPV9WQ5TPpmxugNDdAYciHozUeU1EfTvJubZi9LfH2LomQF/RSEPKT7fdSXpBFSW5AgrkQn0ECuvjcfB6zU/VJftDLlMpybCfdGMvRHzfI6lip8l9/fo+WeIr97YMkkraDozX5WV765wcpyvYR8BrEU3Z6Hmh+8AuNrBPiRCUBXXxuRSFfp0ET0aRNUchHLGnRPz+A7dgMKAiwcOrHczzLCoI8XlXD2s3VlOYG0vXipoHjkG4FoMFjGHhNg9ygl0FFIQnkQnxOsikqvpCO5Yo+j0E0abOzLsLGHXVcO3EwHtNAt1e5mAqc9g1Pj6FIWDbhhE1ByAso7PZhFUG/QV5AVuRCfJpP2xSVFbr4QgxDURTy0Rq3iKccfrdxN+WFQSadWsodT2+lOZrEcjQ+U7nB3DQUHlPhMU1MQ2E7kO03KS/Ion9BFgVZkicX4nBIQBeuTzq2/1FzjD0NET5silLfFmdvc5Ta1jj14QSzVmzG1polf9tNUbaXgUVZ/ORbIzANA6XAcsBqD+Z+j0HS1mit6ZPtp7wgi/wsWZEL0V2kbPEEkkmTOI6DrdO568zBHIDdDRH2NETdvuIDC7Nw0Fy3/FW33nzRVWPweRT/+cK7/ORbI6hpimGo9CnQDxpi9M3z4zUNbCedF/eaoLWiKOgjEJC/bkIcSbJCP0FkDgP99q/vE0nafNQc462PWvnpk1vYvr+N1niS/a3x9AnOpRuZ99Rb7G+L0xRJuSWKNU0x5j76Gh7DZEplObvro5QVBHnqtRoemFHJ/S+9T1M0haM1hlKkHE3C0hgG1EbSK34hxJEjAf0E0RBJ8v9eq2baWYNojCTdY/TXThjMr/68nUjCdnumQDp437JmC32yOze6Ks724/cYDCvJJuA1WDKjktVVNax7ez8/u2gkuQEvpkq3tm2NpZj/zFbCcZvatgT14cSx+K0LccKQKpcTxP6WGPtaE3z3dx/P2VwwZRTv7Wvh6yP7pY/cK0VrPEVrLEXAa1Ka60frdA7c70mnUZqiKeasrHLfY+UN41CZShXTADS2A4teer/TKLkxg4o4tW8O5QVZkjMX4jBIL5cTROdSws5Nq2pb42z9qJUsn0lzLMXidTu4ZHRfzhzch9kdAvT9088gL+hDa4dw0nEbZv34/OEopfjR79/sdEq0rCDIr6edTnPU4qSiLJKWQ0GWl2gyfThozeYPOGd4KQ9v2MVPvjWCbL9XZnoKcRikl8sJ4MCGWZm2sqah8HoMWuMp5j31lhu4f3nZaPrlB5i+7JVOPVmiSZvv/u4VHv7OOG5qD/TzJldwy5otPDTzzE7BHNKpmcKQn+aoxY8ef5O6cIInbjobSM8DHTOoiIc37GLmxMHsa4lzUqFk+YQ4UiSg9xIdG2adUZ7PtRMGM/23r3Raef962unkB33YWlMfTmLZuktPlkwe3VSqy+Qgs72a5cAVuqEUQZ/JPZePpq4tgc9j4MQt2uIW+UEv08YNJOgzWfTS+/zi0lFH/c9GiBOFBPReomPDrDmThvLwhl3Mm1xBftCLz6MoCPlI2ZrdDVHue/E96sIJHr3hrE4BuuPIt8w0ocwkobKCIPta410GTiycOgqlNC2xFA/+305++I3h5AZ8ZPu8+EyD2rYESdth0Uvv88NvDJdpQkIcQZJD7yXq2hL89MktTKks55TSbLSG1Zv28JVTShhQEEz3SjGVe/z+1y++T0GWh4vPKGP2I+nUyvLrznTTMk99dwKGUtz06GtuDn35+l3MPfdkmiIpt1a9vDBINGmT5TMJek365QXdvP2n5fSFEF+MbIqeACzL4Z39bW4FyjcrSvjphRU0R1Psa42ztqqa7593CrlBD44DHhNqW5M8/9ZHXDNhMLGUTcjvoTGcZHb7RuhdU07D7/GgFPg8BomUQ8JKX6e1JmlrHt+0x930/MWlo2TDU4gjTDZFTwBNsY/LCW/++jD+cUwZKdshO+ChzAjyk2+NQKHwmwZJNAr4/mOvM29yBY6G65a/SnG2n/umnc78S04jy2eilMJrKpRKr7YNlR5M8fqeBk4/qYimSMLd9JR0ihDHnpQc9BKZHPrllWVMOrWUacs28sc3P8JnGhSE0vlsQ7XXlHsVlqPdARSO1jxw1Rjqwgl+/eL7FGX7uPn3b/LNX/2NP2/di6MhYTkkLIdHNuyiT06QSDJFPJVum3vHxacxvDRH0ilCHGOyQu8lMkMnZp0zhJkPvcoVlWVMGlHKypd3ccW4gTRGkqTsdI245aQnAmUGUPzl7X1MHz+IldeflR7M7DNZfeN4rPZ+LI9s2MXl4wZiGooZZ6fLD3+y9i3qwgmWXTOWvjJNSIgeQVbovURm6IRppMsNLxlTxq9ffJdvjRrANQ9u4hd/fBuPodjbkmDOyioU2h1Acc7wUl56ex9+b3rARCLlUNeWoCma5N//tI0LRw8gnrIxDcUbHzQwoH0o9JNzJ8rKXIgeRAL6cS5dSRLno5YYeUEPfo9BWUEQR2umVJa7R/3nTBrKDx9/0531Wd0UI8tnMnfSyQwsCvLlU0ppiSaxHAdDQZ8cPyU5fu64aCQFWemUze827ubk0jz65gYYUJAl4+GE6GEkoB/HHEezuyHCu/vCXLl0IxPueokVG3bxwIxKTJUeQHFgjXmmpvzu57ZjKEVTNEUsaeP3GAR9HryGwV/e3kdLNIXlaEpyAgS8HrJ8Jjecc7KsyIXowSSgH8caIkn2NEQ7dUlc8rfdPPNGDSG/QXGO3537mQnki9ftYMGUUdSFE/zsqa3p1bfHBNKliRrNeRX96Jvvp39uEI8n/T6yIhei55OAfhxLWrabQuloyd920xy1eGVHPUtmVLqB/FeXj6YunOCe57cz/5LT+OXloynK9pMbNFEKkpaDQpHlMygI+vF45K+HEMcTqXI5jnnbhzMfrL+K7Wjue2kHv7r8dJZfdyamodjfGue/rjidwpAPn8dAkS5j/Kg5QdBrsnrTHv5xTDn98yWtIsTxSE6KHscaInH2NcdpjVud+qs8cNUYnnnzQyadWkqfHD8Ln3uHKZXlzH9mmxv4zyjP5/vnDWNgURaOhqDXwOsx6BOStIoQPZkc/T9OHKz3CeA+p5RCKY3jgNc0iKVsfvDYG/zsohH0yQ7gaI3XUHhMRcLSOFrz0tv7OHdEXyzbIZZyOg2nWHJ1JX1CPgzDkD4rQhwn5Oh/D+c4mvpIgmjCpjmapCDkIxFPkbRsPIYimrLxGAZoB1A0RZNorSkM+akLJ7h00cvue83+yiCu/8oQ9/HXR/bDZyraHM3mXfX87oazMA0lzbKE6IVk1+sYy5Qebv2wlf2tcZqi6UC+vzXOnX/Yys76CP+8+k2mLdvIB40x5j+zlUjCAkApzb1Xnu5WspQVBJl0aikocLSmri3B7voIexpiGArOq+hHKGBKxYoQvdQhpVyUUucD9wIm8Fut9V0HvP7PwA2ABdQB39Fa7/m095SUS1pjJEF1Y5SkpemT7cPW4DEUluO0z/FMX1fTFGXFy7vdXPj8S05jRL9swgmbcNwiP8uH2Z5usR2H/9m6j4nDSjAN5Y6CGzOoiBH9cjmpMOuY/p6FEF/cp6VcPnOFrpQygfuBC4AKYJpSquKAy14HxmqtRwFrgLsP75ZPHCkrHbEtx+GxTXvQOp37DnhN/F6DXfURfrj6DW574u9c/+Uh9M8LUNN+yjNlQ1MkRUHIh+U4WLbD7voI9/3P+4wd3IeZD73K1375v8x86FXOGV7K2qpqTFmUC9FrfeYKXSl1NnCH1vof2h//BEBr/R+fcP0ZwG+01hM/7X1lhZ5Ot+xtiWHr9NAJR4PtaGxHs3rTHiaPLuOZN2u4YFR/tNbtvcYVScvB51HYDuxridMcS3WqYAH44z99maDPpDGSpCGSZG1VNTMnDmZ43xwKQ9KzXIjj1WGt0IEBQHWHxzXtz32S64FnP+FGblRKbVZKba6rqzuEj+69MkOd7/zDVhojSdriKZKWg9aQHfBw/VeGUBDycu3EwWT7PRhKUd0Y48qlG7n58Tepboyxsy5CNGmztqqaBVNGdcql+73pf7Ud53qW5gbID0rPciF6q26tclFKzQDGAl892Ota66XAUkiv0Lvzs483maHO8yZX4DUMkpbm+oc3MWFIEbPOGUx9OMkta7Ywb3IFPjMdnDPj4eZNruCWNVsozvaz8LJRzJw4mOXr0zNEi0I+irJ95Pg9FIb85AS8MgJOiBPEoQT0D4HyDo/L2p/rRCn1deCnwFe11onuub3eKzOQIj/oJTfoZdqyjdQ0xZh1zpB00G4P3vlBr/s9BzbaqmmKEUlYlBWkJxLZjqY+nKQ1liIv6MUwlIyEE+IEcigpl1eBYUqpwUopH3Al8HTHC9rz5kuAi7XWtd1/m71PZiBFcyyF3T49CMA0VKf+LM2xFNGk7R7xzzyX+fqOp7fREEmyuz5KQzhJLGmTE/BKakWIE9BnBnSttQV8D3geeBt4XGu9VSn1c6XUxe2XLQSygd8rpd5QSj39CW93QnOcdG34h01RTAOWXT2WtVXVeAzlBmjb0Z2C9+J1OygIeSkMeVk4dZTbaCvz9evVzSx66X2GFocoKwhy2oA8BhWFJLUixAlIjv4fJZlN0FkrNlPTFOObFSXccfFItu8LM3JADvtbk9y0sqpLDr3jtYZSpOx0WWO238TW6bJHyY8LceKQXi49QF1bgksXrf+4b/nVlRSFfExd/DKrbxxPYciLYRiYhiLkM9GOJtlewqiApmiSlJ0uXRyQF5TWtkKcoKSXSw+Q2QTNyA96aYgk3Tx6NGm7G6FnlOdz+8UVxJI2y9fvYkplOUUhHyU5fvpLMBdCfAKJDEeB1X4aNJMXh/TGZqZ+fG1VNQUdcuSZvPigoixuv2hk+rh+URZlBVkSzIUQn0hW6EdIpoOiacDe5gT3vfgui64aw9xH00Ob11ZV872vDeM3f3mPKZXleE2D0j4BHrtxPI6jCfhM6U0uhPhcJKB3g0wfc9PQpCyNBhrCSe598V3mTR7p9iD/18kVzJtcQX7Qi2ko8tpPcGb5TGpbE3hNxdrN1dxwzslSPy6E+NwkoB+mTPXKKzvqmHhKCfVtCeIph3lPvcW8yRWkbMfNndu27tRz5eavD+Mfx5SRsh23I+I/jil3B1sIIcTnIQnZw+A4mv2tcWat2MzXKvpR0xjjljVb3INB+UEvtqPd3Pm+1ribJwdYXVVDQyRBbVsC01BcN3EIw0tlnqcQ4ouRFfoXlFmZe02DmqYYjtZuIM+c5GyOpfjL2/t4YEYlN62s4u7ntnPHxRXcc9loSnP92A7EkhaxpA1AaW5AgrkQ4guTgP4FZZprPfKdcZQVBDGUck94Ll63g19eNpr//r+dXDthMM+8UcPK68ehlMLvMXA0mArs9uHMffOCcjBICHHYJKB/QZm68kwa5S/b9jLxlBIWTh3FLWu2cNez73DrBadyUmGQQUWDsR2N1zToE/JL6aEQ4oiQgP4FZZpr3f3cdm6/uIKBfXLwmYrBfUI8duN4bEcTjlsolR4LNyAncKxvWQjRy8lS8QsqCvlYds1Y6sIJ7nx6GwC2A/GUw33/8x5X/fYVWuMpbNshnrKP8d0KIU4E0svlICzLoS6cIGk7mIYi6DMoCHY95JM5PBRPORgKFPBRcxxHpzsmFoa8JC1Nv/wAZQUymFkIcfikl8tnsCyHlniSeMrBctLzPWMpm30tcQJek8KQj0jCJuQzyQv43By4YShK2lMpDZE4TZEU4YRFls9039vnUXhls1MIcRSc8AHdshzqInFMlR7SrDUkLAevx2DFy7t5YVttunJlRiVe0+Cj1hj9czs3yLIsh9aYRSRhMbhPCNvRGArqw8l0QJdNUCHEUXDCR5q2RBLHgVgq3UDLY6SP7SdTNt8992QgPfptzsoq9jREaY6maIwm3e93HM1HLTF210e5/6X3aY4l+aAxSm1bgnDCIuT3yPQgIcRR0esDescpQXVtCRzn4z2DVMomlnJI2g4p2/n/27v7GDnq84Dj32dm3/d83JtNjc/mcIAGG1o5puCmIkBNKKAUqwHCS2ioZGEHq2mlkAoklITCXwSSqkl4qVtQqJMGByiJk4YgBbCQICbxYXAA4dbGDnfGxr4Xv9zu7c7OztM/Zu5yPtnxAnu77Pj5SCfN7sztPc/N3nO//c1vfj92HxhnuBC2qotelTntvx+ZMjg6Tk9bijU/eAWvGkw+P1zw2He4zLef/T9u+uRpPPD89sm+94Wz8/R12epBxpjGiHVBn7ib846ntvL6u4f43XCBwdEivh9QKvnsOVzC88MCn0m69HXnOLk9w5z2DJ4fLi4xobcziysS3hUa6OQ/iqLnM1zw2D9W5r5ntnHV0vl0ZJMcLvm0IJUxEQAACntJREFUZVwbc26MaZhYV5vhgsePXxng9svPojufYrjg8YNNuzhY8jjk+eSSLklXcEQQIJMUxis++w6V6MwnmWhY93ZmuffqP2HvoRK9nVnyaZdt7x3mbx54kbf2Hp6c13z/WJnV6/q59fHX6G5LEb6qMcY0RuyGLU5MZev5VQQ4XPZZ+ehmZrel+ecVi+nKp6hGI1kSjuA6gjjw0y27WXpaD/M60pR9ZXBknLkdGXaPjlP0qnTmkzy99V1uWNaH6wjXrd00ubrQXSsW851oXvPufIqufIqHNu7gHy85g3k2XNEYU0d/aNhibFroQaDsO1RiYLTIWLnCOyNF7vzpG4wUPP7h4o/xnRuWcFI0D3k+GlZY8gPK0WpCl54zl/6dQxTKAbuGCnRELfRMMrwjtCuf4solvXz+P15m9+j45BS4WwYOMFb2uf68UyeXlbv1R6/x0tvDpBLuMeM1xph6i0VBn+gr/+yDL3HhvRv524d/DcCai09n256DnH96D54fkHAEUPYcKnPt2k1ceO9Grl27iXcPlMkmHf5y0VwCVf7pia0MjoyjCt1tKfJpF0FYva7/iNkUJ3zjF9vIJB1uffw1Vq/rZ/9YmX//wrk2r7kxpqFiUdAnZj6c6AL56mcWhUu6taf59OK5JB2hPZNARPCrcEu0ghCEo1du+X4/xXJAwgGJLnzmUi5+oKx7aSelStiSn/iehzbu4J6rfj+v+f6xMie3Z/jvNZ/kxdsu5qk1f2HzmhtjGi4WNxZNzHy4ZH4HX/mrP+a2J7dy7dJeLjrrZPp3DrF80R8xUvZIJ1wUJgvzhMHR8ck7RH/yyiC9nVmKXpVAlQvOnAOE0932dmYZHB1ny8AB7ntmG3evOJuPzc6TTSVs+ltjTNPFooWeSrjc+ZmP890bltDbmWX9qmV8dmkvP3t1kMvOOYWyr+weDe8GdUWO6C6BsFCLCGU/YH3/YLiqUFeWTNJlQXeOTNJlaMw7YrWh/WNlMkmHtkyC2bNsMWdjTPPFYpRLqeQzPO7hB0o64VCpKoEqnh+QSjhUozHjC7pzgDI0VpnsduntzPLgjUvp3znEJYvnApByBRC6cuG8LUGg7BoucLhUYaRQIZdyKXpVTu3O0ddtNw4ZYxon1pNzlUo+B8sVXEdQonlYnLAlXo2GJVaq4eyH4WLMAad0pFm/ahl+oDgiPPvmHv5sYQ9taYehMY9cKk1XPj35MxxH6OvOc2Dco6etSlUhkwwXq7Biboz5qGjZgh4ESsEr896hCoWyT9GrhqNTRsdZfUEfKy9YSAqHpCNUXZjXmWHc83FE2HugTFdbCheoBhpeOE0Ib+0tMGdW+qhzrziOhEU+3/hcjTGmFi1Z0INA2X2giCvCwEh4gfOrP3l98mLn1ecu4J2RcU7pSJNJOZSrQkcuiQZhYa74AZ4fzreSSgjVQBn3lIU9eXrarNVtjGlNNV0UFZHLRGSbiGwXkduPsj8tIuuj/S+LSF+9A51quOBR9pVKoORSLrmUe8TIFdcRhgse2/YWeOC5HXTmXAiY7JLxA8V1BFQplgNUhXknZZnTnrFiboxpWcct6CLiAvcDlwOLgOtFZNG0w1YCo6p6OvAvwD31DnQqz6/iSFi4i16Volc9YuRKNVCe7B+gM5/koo+fzOX/+hKrv/8KA9HNQhKtLiQitGeTzOvI2iRaxpiWV0sVOw/Yrqpvq6oHPAasmHbMCuDRaPsJYLmIzFhTN5VwCRRSrkNXPklXPnnEkMInNr/Dl5afyQPPbyeTdPjhzcu475o/pexXuftnbzBarJBNuczrzNmQQ2NMbNTShz4PGJjyeBA4/1jHqKovIgeBbmCoHkFO151PMV7xUQLy6QSjhQoLunI8tmoZQXSDUC7t8PW/XkylqihKMiHMyiS5/fKzSLpii04YY2KnoRdFRWQVsApgwYIFH/h1HEc4pT3LSLFMd1uSbDK8TT/pOmRSDn6glCqKAo4DrgiOQE9bimzKpSNrd3UaY+KnloK+G5g/5XFv9NzRjhkUkQRwEjA8/YVUdS2wFsIbiz5IwBMSCYeetgxDY2Wq0UVOV8B1oCObtj5xY8wJp5aC/hvgDBE5jbBwXwfcMO2YDcBNwK+Aq4HntAG3oDqOHLFMnDHGnMiOW9CjPvG/B54BXOARVX1DRO4CNqvqBuBhYJ2IbAdGCIu+McaYBqqpD11Vfw78fNpzX5uyXQKuqW9oxhhj3g/raDbGmJiwgm6MMTFhBd0YY2LCCroxxsSEFXRjjIkJK+jGGBMTTVuCTkT2A7+rw0v1MENzxnxEWb7xdSLlCpbvB3Wqqs4+2o6mFfR6EZHNx1pfL44s3/g6kXIFy3cmWJeLMcbEhBV0Y4yJiTgU9LXNDqDBLN/4OpFyBcu37lq+D90YY0woDi10Y4wxWEE3xpjYaJmCLiKXicg2EdkuIrcfZX9aRNZH+18Wkb7GR1k/NeT7ZRF5U0S2isizInJqM+Ksh+PlOuW4q0RERaSlh7rVkq+IfC46v2+IyH81OsZ6quG9vEBEnheRLdH7+YpmxFkPIvKIiOwTkdePsV9E5NvR72KriHyirgGo6kf+i3BhjR3AQiAFvAYsmnbMGuChaPs6YH2z457hfC8GctH2La2aby25RsfNAl4ANgHnNjvuGT63ZwBbgM7o8Zxmxz3D+a4Fbom2FwG7mh33h8j3U8AngNePsf8K4GlAgGXAy/X8+a3SQj8P2K6qb6uqBzwGrJh2zArg0Wj7CWC5iLTqStDHzVdVn1fVYvRwE+Far62olnMLcDdwD1BqZHAzoJZ8bwbuV9VRAFXd1+AY66mWfBVoj7ZPAt5tYHx1paovEK7adiwrgP/U0CagQ0Tm1uvnt0pBnwcMTHk8GD131GNU1QcOAt0Nia7+asl3qpWE//Vb0XFzjT6WzlfV/2lkYDOklnN7JnCmiLwoIptE5LKGRVd/teR7J3CjiAwSroz2pcaE1hTv92/7falpCTrz0SUiNwLnAhc2O5aZICIO8C3g75ocSiMlCLtdLiL85PWCiJyjqgeaGtXMuR74nqp+U0T+nHB94rNVNWh2YK2mVVrou4H5Ux73Rs8d9RgRSRB+dBtuSHT1V0u+iMglwB3AlapablBs9Xa8XGcBZwMbRWQXYb/jhha+MFrLuR0ENqhqRVV3Av9LWOBbUS35rgR+BKCqvwIyhBNZxVFNf9sfVKsU9N8AZ4jIaSKSIrzouWHaMRuAm6Ltq4HnNLoK0YKOm6+ILAH+jbCYt3If6x/MVVUPqmqPqvapah/h9YIrVXVzc8L90Gp5L/+YsHWOiPQQdsG83cgg66iWfN8BlgOIyFmEBX1/Q6NsnA3AF6LRLsuAg6q6p26v3uyrwu/j6vEVhC2VHcAd0XN3Ef5xQ/gmeBzYDvwaWNjsmGc4318C7wGvRl8bmh3zTOU67diNtPAolxrPrRB2M70J/Ba4rtkxz3C+i4AXCUfAvApc2uyYP0SuPwT2ABXCT1orgS8CX5xybu+Pfhe/rfd72W79N8aYmGiVLhdjjDHHYQXdGGNiwgq6McbEhBV0Y4yJCSvoxhgTE1bQjTEmJqygG2NMTPw/W3PTUkCMoXgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=y, y=y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00045468888669267726"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(input_shape)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1351/1351 [==============================] - 4s 3ms/step - loss: 0.0286\n",
      "Epoch 2/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0037\n",
      "Epoch 3/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0038\n",
      "Epoch 4/10\n",
      "1351/1351 [==============================] - 2s 2ms/step - loss: 0.0041\n",
      "Epoch 5/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0029\n",
      "Epoch 6/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0035\n",
      "Epoch 7/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0031\n",
      "Epoch 8/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0026\n",
      "Epoch 9/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0022\n",
      "Epoch 10/10\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f386279bc90>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= X, y=y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(input_shape), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0011\n",
      "Epoch 2/30\n",
      "1351/1351 [==============================] - 1s 981us/step - loss: 0.0011\n",
      "Epoch 3/30\n",
      "1351/1351 [==============================] - 1s 956us/step - loss: 0.0012\n",
      "Epoch 4/30\n",
      "1351/1351 [==============================] - 1s 970us/step - loss: 0.0011\n",
      "Epoch 5/30\n",
      "1351/1351 [==============================] - 1s 998us/step - loss: 9.6143e-04\n",
      "Epoch 6/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0010\n",
      "Epoch 7/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0011\n",
      "Epoch 8/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0012\n",
      "Epoch 9/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0010\n",
      "Epoch 10/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 9.9266e-04\n",
      "Epoch 11/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 9.7646e-04\n",
      "Epoch 12/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0011\n",
      "Epoch 13/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 9.6052e-04\n",
      "Epoch 14/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 9.3177e-04\n",
      "Epoch 15/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 9.9102e-04\n",
      "Epoch 16/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 7.7605e-04\n",
      "Epoch 17/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 7.2456e-04\n",
      "Epoch 18/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 0.0013\n",
      "Epoch 19/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 7.5203e-04\n",
      "Epoch 20/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 7.6058e-04\n",
      "Epoch 21/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 6.3449e-04\n",
      "Epoch 22/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 7.8306e-04\n",
      "Epoch 23/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 7.3329e-04\n",
      "Epoch 24/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 6.5993e-04\n",
      "Epoch 25/30\n",
      "1351/1351 [==============================] - 1s 983us/step - loss: 6.2777e-04\n",
      "Epoch 26/30\n",
      "1351/1351 [==============================] - 1s 969us/step - loss: 5.4805e-04\n",
      "Epoch 27/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 5.6316e-04\n",
      "Epoch 28/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 5.0348e-04\n",
      "Epoch 29/30\n",
      "1351/1351 [==============================] - 2s 1ms/step - loss: 7.8036e-04\n",
      "Epoch 30/30\n",
      "1351/1351 [==============================] - 1s 1ms/step - loss: 5.7061e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f386205be50>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= X, y=y, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitSequence as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[(0, 'Date'), (1, 'Open'), (2, 'High'), (3, 'Low'), (4, 'Close')]\n"
    }
   ],
   "source": [
    "data2 = data.iloc[:,:5]\n",
    "print(list(enumerate(data2.columns)))\n",
    "data2 = np.array(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1105\n"
    }
   ],
   "source": [
    "split = round(len(data2) * 0.8)\n",
    "print(split)\n",
    "train = data2[:split,:]\n",
    "test = data2[split:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitSequence as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sq.timeseriesSplitTestTrain(data2, proportion=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(276, 5)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We should standardize the training and testing set separately, to avoid look-ahead bias\n",
    "https://datascience.stackexchange.com/questions/47008/is-normalizing-the-validation-set-of-time-series-a-kind-of-look-ahead-bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.75902262, 68.55434299, 66.90387249, 67.74956109])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized = scaler.fit(train[:,1:])\n",
    "standardized.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitSequence as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_open = sq.splitSeqGetX(train[:,1], 50)\n",
    "X_train_close = sq.splitSeqGetX(train[:,4], 50)\n",
    "ytrain = sq.splitSeqGety(train[:,1], 50)\n",
    "X_test_open = sq.splitSeqGetX(test[:,1], 50)\n",
    "X_test_close = sq.splitSeqGetX(test[:,4], 50)\n",
    "ytest = sq.splitSeqGety(test[:,1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1055, 50, 4)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "col_index = [1,2,3,4]\n",
    "for i in col_index:\n",
    "    X.append(sq.splitSeqGetX(train[:,i], 50))\n",
    "np.dstack(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1055, 50, 3)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = np.dstack((X_train_open, X_train_close))\n",
    "Xtest = np.dstack((X_test_open, X_test_close))\n",
    "Xtrain.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Xtrain.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(input_shape), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 5588.2935\n",
      "Epoch 2/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 5048.2004\n",
      "Epoch 3/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 4281.0692\n",
      "Epoch 4/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 3397.8134\n",
      "Epoch 5/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 2555.3250\n",
      "Epoch 6/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1881.8009\n",
      "Epoch 7/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1434.9083\n",
      "Epoch 8/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1197.0598\n",
      "Epoch 9/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1098.0957\n",
      "Epoch 10/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1065.9476\n",
      "Epoch 11/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1058.1793\n",
      "Epoch 12/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1056.4671\n",
      "Epoch 13/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 1046.6342\n",
      "Epoch 14/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 751.4777\n",
      "Epoch 15/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 362.1205\n",
      "Epoch 16/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 220.7976\n",
      "Epoch 17/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 142.1488\n",
      "Epoch 18/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 95.5249\n",
      "Epoch 19/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 63.2929\n",
      "Epoch 20/20\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 42.0140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1b0c39b050>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=Xtrain, y=ytrain, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(x= Xtest, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.27552222027465"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(mean_squared_error(ytest, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitc736265aa96942798be544ff59087e30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-candidate"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}